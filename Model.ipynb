{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import pandas as pd\n",
    "from skimage import io, transform\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (local_conv): Conv2d(1, 64, kernel_size=(1, 6), stride=(1, 1))\n",
      "  (global_conv): Conv2d(64, 128, kernel_size=(20, 2), stride=(1, 1))\n",
      "  (dec): LSTM(128, 48, num_layers=2, dropout=0.25)\n",
      "  (denseFF): Linear(in_features=48, out_features=7, bias=True)\n",
      "  (sm): Softmax()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class Net(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        # 1 input image channel, 64 output channels, 1x6  convolution\n",
    "        # kernel\n",
    "        self.local_conv = nn.Conv2d(1, 64, (1,6))\n",
    "        \n",
    "        # 64 input channels (check this?), feature maps from local convolution,\n",
    "        # 128 output channels, 20x2 kernel (check this?)\n",
    "        self.global_conv=nn.Conv2d(64,128,(20,2))\n",
    "        \n",
    "        #LSTM layer,48 cells each,  how to set 0.25 dropout rate ???\n",
    "        self.dec=nn.LSTM(128,48,2,dropout=0.25)\n",
    "        \n",
    "        # Size of output of LSTM, for now use # of hiden state features\n",
    "        self.denseFF=nn.Linear(48,7)\n",
    "        self.sm=nn.Softmax()\n",
    "        \n",
    "    def forward(self, x,hidden):\n",
    "        # Apply ReLu units to the results of convolution, local convoltion layer\n",
    "        x=F.relu(self.local_conv(x))\n",
    "        x=nn.MaxPool1d(4)(x)\n",
    "        \n",
    "        #Global convolution layer\n",
    "        x=F.relu(self.global_conv(x))\n",
    "        x=nn.MaxPool1d(2)(x)\n",
    "        \n",
    "        out,hidden=self.dec(x,hidden)\n",
    "        \n",
    "        # Feed output through dense dense/feedforward layer with softmax activation units to \n",
    "        # classify the input onto one of the 7 emotion categories.\n",
    "        out=self.sm(self.denseFF(out))\n",
    "        return out\n",
    "        \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training \n",
    "\n",
    "\n",
    "initial_data = pd.read_csv('./RawTrainingFeatures1.csv',header=None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          0    1    2    3    4    5    6    7    8    9     ...      \\\n",
      "0  '03a01Fa'  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0    ...       \n",
      "1  '03a01Fa'  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0    ...       \n",
      "2  '03a01Fa'  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0    ...       \n",
      "3  '03a01Fa'  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0    ...       \n",
      "4  '03a01Fa'  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0    ...       \n",
      "\n",
      "         80        81   82   83   84   85    86   87        88         89  \n",
      "0  0.021276  0.013531  0.0  0.0  0.0  0.0  0.02  0.0 -55.36968  happiness  \n",
      "1  0.017773  0.013590  0.0  0.0  0.0  0.0  0.02  0.0 -55.01866  happiness  \n",
      "2  0.016929  0.014316  0.0  0.0  0.0  0.0  0.02  0.0 -55.47804  happiness  \n",
      "3  0.018678  0.015873  0.0  0.0  0.0  0.0  0.02  0.0 -56.35629  happiness  \n",
      "4  0.021022  0.016501  0.0  0.0  0.0  0.0  0.02  0.0 -57.43427  happiness  \n",
      "\n",
      "[5 rows x 90 columns]\n"
     ]
    }
   ],
   "source": [
    "print(initial_data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EmotionDataset(Dataset):\n",
    "    \"\"\"Face Landmarks dataset.\"\"\"\n",
    "\n",
    "    def __init__(self, csv_file_path, transform=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            csv_file (string): Path to the csv file with annotations.\n",
    "            root_dir (string): Directory with all the images.\n",
    "            transform (callable, optional): Optional transform to be applied\n",
    "                on a sample.\n",
    "        \"\"\"\n",
    "        self.emotions_frame = pd.read_csv(csv_file_path,header=None)\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.landmarks_frame)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        features = self.emotions_frame.iloc[idx, 1:-1].as_matrix()\n",
    "        label=self.emotions_frame.iloc[idx,-1]\n",
    "        speaker=self.emotions_frame.iloc[idx,0]\n",
    "        features = features.astype('float').reshape(88)\n",
    "        sample = {'speaker': speaker, 'label': label,'features':features}\n",
    "\n",
    "        if self.transform:\n",
    "            sample = self.transform(sample)\n",
    "\n",
    "        return sample\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Code to train \n",
    "model=Net()\n",
    "first_pass_data=EmotionDataset('./RawTrainingFeatures1.csv')\n",
    "loss_fn = torch.nn.LogSoftmax()(reduction='sum')\n",
    "learning_rate = 1e-4\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "for i in range(len(first_pass_data)):\n",
    "    sample=first_pass_data[i]\n",
    "    features=sample['features']\n",
    "    y_pred=model(features)\n",
    "    loss=loss_fn(y_pred,sample['label'])\n",
    "    \n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
